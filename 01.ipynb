{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1: The Golem of Prague\n",
    "\n",
    "https://www.youtube.com/watch?v=FdnMWdICdRs&list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus&index=2&t=7s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This lecture introduces a framework for scientific thinking and data analysis that moves beyond the limitations of traditional null hypothesis testing. It advocates for a workflow that integrates causal modeling, statistical analysis, and rigorous testing, emphasizing the importance of transparency, documentation, and ethical practice.\n",
    "\n",
    "Here's a summary of the key concepts:\n",
    "\n",
    "### **Moving Beyond Null Hypothesis Testing**\n",
    "\n",
    "- **The traditional focus on rejecting null hypotheses is often inadequate for complex research questions.** Many scientific fields have encountered issues with null hypothesis testing, particularly when there is no clear or unique null model.\n",
    "- **Examples of this failure include:**\n",
    "  - Population genetics: The neutral theory of molecular evolution cannot be definitively proven by rejecting null models of selection.\n",
    "  - Ecology: Permutation methods for analyzing species co-occurrence can produce misleading results because they fail to account for underlying ecological factors (as discussed in our conversation).\n",
    "  - Social network analysis: Permutation tests for network structure often lack statistical power and can lead to false conclusions.\n",
    "\n",
    "### **DAGs (Directed Acyclic Graphs)**\n",
    "\n",
    "- **DAGs are visual representations of causal models that make assumptions transparent.** They help researchers identify potential confounders and select appropriate control variables.\n",
    "- **By analyzing a DAG, one can determine the correct variables to include in a statistical model, avoiding the pitfalls of blindly adding controls.**\n",
    "\n",
    "### **Golems (Statistical Models)**\n",
    "\n",
    "- **Statistical models are powerful tools (\"Golems\") that can be dangerous if misused.** They must be designed and implemented responsibly, with a clear understanding of their limitations.\n",
    "- **The lecture criticizes the \"flowchart\" approach to statistical testing**, which often leads to the inappropriate application of statistical procedures.\n",
    "\n",
    "### **Owls (Workflow)**\n",
    "\n",
    "- **\"Drawing the owl\" represents the importance of a systematic and well-documented workflow in data analysis.** This helps ensure understanding, reduces errors, and promotes reproducibility.\n",
    "- **The Bayesian framework is presented as a powerful approach for integrating causal modeling and statistical analysis.**\n",
    "\n",
    "### **The Proposed Workflow (\"Drawing the Bayesian Owl\")**\n",
    "\n",
    "1. **Define the theoretical estimate**: Clearly articulate the research question and the quantity you want to measure.\n",
    "2. **Design a causal model (DAG)**: Represent the hypothesized causal relationships between variables. Develop a **generative model** that can simulate data based on these relationships.\n",
    "3. **Build statistical models**: Choose and implement statistical procedures that are appropriate for the research question and justified by the causal model.\n",
    "4. **Test and validate the models**: Use simulated data from the generative model to ensure the statistical procedures are working correctly and producing reliable estimates.\n",
    "5. **Analyze the real data**: Apply the validated models to the actual data.\n",
    "\n",
    "**In conclusion, the lecture advocates for a more thoughtful and rigorous approach to data analysis, one that emphasizes the integration of causal reasoning, statistical modeling, and careful testing. This workflow, symbolized by \"drawing the Bayesian owl,\" aims to promote scientific rigor, transparency, and ethical practice.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 components: DAGs, Golems, Owls\n",
    "\n",
    "## DAGs\n",
    "\n",
    "For statistical model to have any insight into a real world problem, it must be linked to a _scientific_ causal model. The causal model defines the relationships - changing one variable changes only a subset of the effects. In abscence of a causal model, the stat model can find any cause it wants. In this light, we need to provide it with a causal structure, that we can then test. \"The cause of the data cannot be extracted from the data alone\"\n",
    "\n",
    "Causal inference can be thought of as knowing what would happen when an \"intervention\" is applied. If you see the tree swaying outside, and the cause is wind, then changing the wind speed/qty should change will have an effect on it. It is not just a association of wind and swaying params, that is statistical and bidirectional (swaying manually creates local wind), but causal inference is the effect of an intervention.\n",
    "\n",
    "Causal inference also enables imputation - what would happen if something else happened?\n",
    "\n",
    "Even for descriptive model (that works with some observations), you need to have a causal model - because the data itself has causes, that can effect to what extent and ability you can work with the data.\n",
    "\n",
    "DAGs - Directed Acyclic graphs! Very abstract causal models. What causes what, not relationships are there (DAGs dont care if there is a linear/nonlinear rel, for example).\n",
    "\n",
    "X->Y : treatment->outcome\n",
    "if a variable influences both X AND Y, it is a confounding variable. We want to control for it, as something that effects both of them can make the analysis unreliable.\n",
    "\n",
    "DAGs are useful for doing science and help mention intuition - get out of data, and start doing science. They also help more explicitly see what the test and refinement procedures should be.\n",
    "\n",
    "## golems\n",
    "\n",
    "What the course calls statistical models - can be big and powerful, but dont have wisdom or foresight.\n",
    "\n",
    "The normal \"flowchart following\" way of doing statistics is very limiting. Unless you have control over the experimental setting, you're probabably studying more complex observational data, where it's hard to define a \"null hypothesis\" (or a neutral state so that a deviation from it can be measured) to reject. What we do instead is make multiple process/generative models, and study their implications on the real data.\n",
    "\n",
    "This example will illustrate how trying to form null hypotheses in situations where it is hard to do so, can lead to incorrect outcomes. In the field of community ecology, Connor and Simberloff used a \"permutation method\" - they had a prescence/abscece matrix of species and locations they were found in. They wanted to see if species co-occurance was random - to do this, they shuffled the matrix, and wanted to see if this matrix looked similar to the observation - if it did, then co-occurance was not random. The matrix structure apparently still encodes/'leaks' information after shuffling - for example, if we have more lowland regions and a few mountain regions, then more points in the lowland regions would still exist. the point is, permutation does not create a suitable null hypothesis to compare against, and its hard to make one to begin with. Bayesian methods would be explicit of the causal relationships and provide uncertainity, too.\n",
    "\n",
    "What we need is generative causal models - something which can generate synthetic data, we test and verify the statistical model on those, then introduce observational data .\n",
    "\n",
    "Covariates/controls - things that can potentially have an influence on the outcome. To better understand this, we need atleast a DAG, and even better a generative model so we can quantify the shape\n",
    "\n",
    "bayesian data analysis is the way to meet the data and be explicit about assumptions, get uncertainity. the resultant model is a generative model\n",
    "\n",
    "## owl\n",
    "\n",
    "1. Decide what the estimand (thing you want to estimate) is.\n",
    "2. Come up with scientific causal models (can be a dag to begin with, but we want it to be generative in the future)\n",
    "3. use 1,2 to build statistical models\n",
    "4. Use the generative models from step 2, to validate that the models (3) produces the estimand(1)\n",
    "5. analyze the real data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
